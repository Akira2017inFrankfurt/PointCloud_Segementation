{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和加载模型\n",
    "\n",
    "三个核心功能：\n",
    "- torch.save: 将序列化对象保存到磁盘。\n",
    "- torch.load: 将对象文件反序列化到内存，还有助于设备加载数据。\n",
    "- torch.nn.Module.load_state_dict: 使用反序列化函数state_dict来加载模型的参数字典\n",
    "\n",
    "#### 1. 什么是状态字典：state_dict ?\n",
    "\n",
    "在PyTorch中，torch.nn.Module模型的可学习参数，也就是权重和偏差，包含在模型的参数中。\n",
    "使用model.parameters()可以进行访问。\n",
    "\n",
    "state_dict是python字典对象。方便保存 更新 修改和恢复。\n",
    "将每一层映射到其参数张量。\n",
    "（ps 只有具有学习参数的层的模型才有这个）\n",
    "\n",
    "目标优化torch.optim也有state_dict属性，包含有关优化器的状态信息，以及使用的超参数。\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict: \n",
      "conv1.weight \t torch.Size([6, 3, 5, 5])\n",
      "conv1.bias \t torch.Size([6])\n",
      "conv2.weight \t torch.Size([16, 6, 5, 5])\n",
      "conv2.bias \t torch.Size([16])\n",
      "fc1.weight \t torch.Size([120, 400])\n",
      "fc1.bias \t torch.Size([120])\n",
      "fc2.weight \t torch.Size([84, 120])\n",
      "fc2.bias \t torch.Size([84])\n",
      "fc3.weight \t torch.Size([10, 84])\n",
      "fc3.bias \t torch.Size([10])\n",
      "Optimizer's state_dict: \n",
      "state \t {}\n",
      "param_groups \t [{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [140671936644032, 140669854762880, 140669854762240, 140669854762560, 140671945297504, 140672005680416, 140672005368640, 140669859754784, 140672005306480, 140671945320720]}]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 25, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 25)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# 初始化模型\n",
    "model = TheModelClass()\n",
    "    \n",
    "# 初始化优化器\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "# 打印模型的状态字典\n",
    "print(\"Model's state_dict: \")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "        \n",
    "# 打印优化器的状态字典\n",
    "print(\"Optimizer's state_dict: \")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 保存和加载推理模型\n",
    "\n",
    "##### 2.1 保存/加载state_dict（推荐使用）\n",
    "\n",
    "- 保存\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "- 加载\n",
    "\n",
    "model = TheModelClass(*args, ** kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "\n",
    "当保存好模型用来推断的时候，只需要保存模型学习到的参数： torch.save()函数来保存模型的state_dict。\n",
    "这样会给模型恢复提供最大的灵活性。\n",
    "\n",
    ".pt .pth 作为模型文件的扩展名\n",
    "\n",
    "注意，在运行推理之前，必须调用model.eval()去设置dropout和batch normalization层作为评估模式。\n",
    "如果不这么做，可能导致模型推断的结果不一样。\n",
    "\n",
    "另外，load_state_dict()函数只接受字典对象，而不是保存对象的路径。\n",
    "所以在调用这个函数之前，必须反序列化保存的state_dict。\n",
    "\n",
    "\n",
    "##### 2.2 保存/加载完整模型\n",
    "\n",
    "- 保存\n",
    "torch.save(model, PATH)\n",
    "- 加载\n",
    "model = torch.load(PATH)\n",
    "model.eval()\n",
    "\n",
    "以Python pickle 模块的方式来保存模型。\n",
    "\n",
    "缺点是序列化数据受限于某些特殊种类的类而需要确切的字典结构。\n",
    "因为pickle无法保存模型类本身。\n",
    "而是保存包含类的文件的路径。所以自己的代码可能会被打断。\n",
    "\n",
    "#### 3. 加载和保存Checkpoint用于推理/继续训练\n",
    "\n",
    "- 保存\n",
    "\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optmizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    ...\n",
    "}, PATH)\n",
    "\n",
    "\n",
    "- 加载\n",
    "\n",
    "model = TheModelClass(* args, ** kwargs)\n",
    "optimizer - TheOptimizerClass(*args, ** kwargs)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state+dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()\n",
    "或者\n",
    "model.train()\n",
    "\n",
    "当保存成Checkpoint的时候，保存的不仅仅是模型的state_dict。\n",
    "因为优化器的state_dict也很重要，因为它包含作为模型训练更新的缓冲区和参数。\n",
    "其实也可以保存其他项目。比如最新记录的训练损失，外部的torch.nn.Embedding层等等。\n",
    "\n",
    "要保存多个组件的时候，在字典中组织他们并使用torch.save()来序列化字典。\n",
    ".tar 文件扩展名\n",
    "\n",
    "\n",
    "#### 4. 在一个文件中保存多个模型\n",
    "\n",
    "torch.save({\n",
    "    'modelA_state_dict' : modelA.state_dict(),\n",
    "    'modelB_state_dict' : modelB.state_dict(),\n",
    "    ...\n",
    "})\n",
    "\n",
    "加载的时候也是类似Checkpoint\n",
    "\n",
    "剩下的部分其实都很类似。\n",
    "最后的一点还有在cpu和gpu上反复横跳的操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
